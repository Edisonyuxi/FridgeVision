{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JNHONO_aNxpLkDyyyBneCKQRgyIoKx5V","timestamp":1732685859014}],"gpuType":"T4","authorship_tag":"ABX9TyPp1+bHI1RLYlqd2ed466p9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Three Parts:\n","\n","\n","\n","1.   YOLO part for object detection ---> Output: Cropping Images\n","2.   EfficientNet part for classfication on cropped images. ---> Output: Food vector\n","3.   NER for recipe recommendation\n","\n"],"metadata":{"id":"Lr4Qll2ey5Wf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGI43eNwzSWT","executionInfo":{"status":"ok","timestamp":1732742948724,"user_tz":300,"elapsed":23270,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"99a904d3-d0b5-4bf4-d78d-1083e032cdca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Part 1: YOLO"],"metadata":{"id":"e1m_heNNzM6J"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IT7zt_xIyqNH","executionInfo":{"status":"ok","timestamp":1732742977961,"user_tz":300,"elapsed":24136,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"e146ece9-91b7-47b6-af1a-71ce15d51b2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting roboflow\n","  Downloading roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\n","Collecting supervision\n","  Downloading supervision-0.25.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n","Downloading roboflow-1.1.49-py3-none-any.whl (80 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading supervision-0.25.0-py3-none-any.whl (181 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: filetype, python-dotenv, idna, supervision, roboflow\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.49 supervision-0.25.0\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 17067, done.\u001b[K\n","remote: Counting objects: 100% (45/45), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 17067 (delta 24), reused 28 (delta 12), pack-reused 17022 (from 1)\u001b[K\n","Receiving objects: 100% (17067/17067), 15.68 MiB | 16.64 MiB/s, done.\n","Resolving deltas: 100% (11714/11714), done.\n","/content/yolov5\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (11.0.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.6)\n","Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.3.38-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (75.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n","  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading ultralytics-8.3.38-py3-none-any.whl (896 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m896.3/896.3 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.38 ultralytics-thop-2.0.12\n","Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","--2024-11-27 21:29:35--  https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241127T212936Z&X-Amz-Expires=300&X-Amz-Signature=82f0ae5054f0d6cd07d55f87a7083932e72a53c1a1c7bacd5cbcc8cca767ed0b&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-11-27 21:29:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241127T212936Z&X-Amz-Expires=300&X-Amz-Signature=82f0ae5054f0d6cd07d55f87a7083932e72a53c1a1c7bacd5cbcc8cca767ed0b&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14698491 (14M) [application/octet-stream]\n","Saving to: ‘yolov5s.pt’\n","\n","yolov5s.pt          100%[===================>]  14.02M  50.7MB/s    in 0.3s    \n","\n","2024-11-27 21:29:37 (50.7 MB/s) - ‘yolov5s.pt’ saved [14698491/14698491]\n","\n","mv: 'yolov5s.pt' and '/content/yolov5/yolov5s.pt' are the same file\n"]}],"source":["# import libraries:\n","\n","!pip install roboflow supervision opencv-python\n","import torch\n","from roboflow import Roboflow\n","import supervision as sv\n","import cv2\n","import os\n","from PIL import Image\n","\n","!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt\n","from yolov5.models.yolo import Model\n","from yolov5.utils.dataloaders import LoadImagesAndLabels\n","from yolov5.utils.general import check_dataset\n","\n","\n","!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt\n","!mv yolov5s.pt /content/yolov5"]},{"cell_type":"code","source":["%cd /content/\n","rf = Roboflow(api_key=\"Hxf0mSTlVAZoc1jBBQJr\")\n","project = rf.workspace(\"tiffanyzha\").project(\"oneclassfridgedata\")\n","version = project.version(1)\n","dataset = version.download(\"yolov5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDdZalwUi1RB","executionInfo":{"status":"ok","timestamp":1732743433333,"user_tz":300,"elapsed":24193,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"3d52568e-5feb-4462-d495-9080434bf65f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in OneClassFridgeData-1 to yolov5pytorch:: 100%|██████████| 266177/266177 [00:17<00:00, 14999.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to OneClassFridgeData-1 in yolov5pytorch:: 100%|██████████| 11394/11394 [00:02<00:00, 5539.99it/s]\n"]}]},{"cell_type":"markdown","source":["**change data.yaml last three line to:**\n","\n","test: /content/OneClassFridgeData-1/test\n","\n","train: /content/OneClassFridgeData-1/train\n","\n","val: /content/OneClassFridgeData-1/test\n"],"metadata":{"id":"cL-cfuYazZCL"}},{"cell_type":"code","source":["!yolo task=detect mode=val model=/content/best.pt data=/content/OneClassFridgeData-1/data.yaml save=True project=/content/results save_txt=True plots=true"],"metadata":{"id":"339sMbE5iwOk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732743962275,"user_tz":300,"elapsed":22882,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"84bc6073-42c7-4277-f304-625ebeac1484"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.38 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv5s summary (fused): 193 layers, 9,111,923 parameters, 0 gradients, 23.8 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/OneClassFridgeData-1/test/labels... 346 images, 0 backgrounds, 0 corrupt: 100% 346/346 [00:00<00:00, 1768.25it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/OneClassFridgeData-1/test/labels.cache\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 22/22 [00:12<00:00,  1.73it/s]\n","                   all        346       2367      0.963      0.928      0.967       0.76\n","Speed: 0.2ms preprocess, 8.4ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1m/content/results/val2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"markdown","source":["# Below is not for this test set YOLO"],"metadata":{"id":"ZAWEI1YknGW0"}},{"cell_type":"code","source":["!cp -r /content/results/val2 /content/drive/MyDrive/ColabNotebooks/aps360_YOLO_results_11_27"],"metadata":{"id":"2FAV5aLOmcl8","executionInfo":{"status":"ok","timestamp":1732744241105,"user_tz":300,"elapsed":3341,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=/content/best.pt source=/content/test.jpg  save=True project=/content/results plots=True save_txt=True save_crop=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"id":"V_BYgpSHzwcF","executionInfo":{"status":"error","timestamp":1732685311575,"user_tz":300,"elapsed":327,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"dad1560d-4b71-4782-e620-b9b57a0ec52d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"A UTF-8 locale is required. Got ANSI_X3.4-1968","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-ea08c7142542>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolo task=detect mode=predict model=/content/best.pt source=/content/test.jpg  save=True project=/content/results plots=True save_txt=True save_crop=True'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}]},{"cell_type":"markdown","source":["**Now, the result are saved in /content/results folder**\n","**where the cropped image are inside: /content/results/predict/crops/dummy**"],"metadata":{"id":"KEOX0c1g0u4S"}},{"cell_type":"markdown","source":["# Part2: EfficientNet"],"metadata":{"id":"19OxaUbK0-nR"}},{"cell_type":"code","source":["# import libraries:\n","\n","!pip install ultralytics torch torchvision matplotlib\n","!pip install optuna\n","\n","import os\n","import zipfile\n","import shutil\n","import random\n","import torch\n","import optuna\n","import cv2\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKUiJuFk08ez","executionInfo":{"status":"ok","timestamp":1732681634662,"user_tz":300,"elapsed":6824,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"eab0f886-7beb-4a75-b248-d179fb8d70b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.38)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}]},{"cell_type":"code","source":["# NO need for this\n","\n","# # Unzip the dataset\n","# import zipfile\n","# import os\n","\n","# zip_path = \"/content/new_dataset.zip\"\n","# data_dir = \"/content/\"\n","\n","\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(data_dir)\n","\n","# print(\"Dataset unzipped successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LY_3TsK91PaA","executionInfo":{"status":"ok","timestamp":1732681985565,"user_tz":300,"elapsed":9160,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"3015c56d-47fa-498e-8ef3-fb3d74c5ffff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset unzipped successfully!\n"]}]},{"cell_type":"code","source":["# Step 2: Define Transformations and Load Dataset\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# train_dir = '/content/new_dataset/train'\n","# test_dir = '/content/new_dataset/valid'\n","\n","# train_data = datasets.ImageFolder(train_dir, transform=transform)\n","# test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","# test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","#num_classes = len(train_data.classes)\n","classes =  ['apple', 'asparagus', 'bacon', 'banana', 'basil', 'beans', 'beef', 'bell pepper', 'bitter gourd', 'blueberries', 'bok choy', 'bread', 'broccoli', 'butter', 'cabbage', 'carrot', 'cauliflower', 'cheese', 'chicken', 'chillies', 'chocolate', 'coriander', 'corn', 'cream', 'cucumber', 'egg', 'eggplant', 'eggs', 'fish', 'flour', 'garlic', 'ginger', 'green beans', 'green chilies', 'green pepper', 'ham', 'jam', 'juice', 'lemon', 'lettuce', 'lime', 'meat', 'milk', 'mushroom', 'olive', 'onion', 'orange', 'parsley', 'potato', 'pumpkin', 'red bell pepper', 'salami', 'sauce', 'sausage', 'shrimp', 'spinach', 'strawberry', 'sugar', 'sweet potato', 'tomato', 'watermelon', 'yellow bell pepper', 'yoghurt']\n","\n","num_classes = len(classes)\n","print(f\"Number of classes: {num_classes}\")\n","\n","# Step 3: Define EfficientNet Model\n","def load_efficientnet_model(num_classes):\n","    model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n","    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n","    return model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqpI_DDP1dOj","executionInfo":{"status":"ok","timestamp":1732683847104,"user_tz":300,"elapsed":264,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"65280fb3-3ae9-46df-8dd5-948fa8f35915"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 63\n"]}]},{"cell_type":"code","source":["# Step 4: Train EfficientNet Model with Optuna\n","\n","\n","# ONLY UNCOMMENT THIS IF YOU WANT TO TRAIN\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# def evaluate_model_and_plot_random_correct_examples(model, loader, device, num_samples=3):\n","#     model.eval()\n","#     all_preds, all_labels = [], []\n","#     correct_examples = []\n","\n","#     with torch.no_grad():\n","#         for images, labels in loader:\n","#             images, labels = images.to(device), labels.to(device)\n","#             outputs = model(images)\n","#             _, preds = torch.max(outputs, 1)\n","\n","#             all_preds.extend(preds.cpu().numpy())\n","#             all_labels.extend(labels.cpu().numpy())\n","\n","#             for i in range(len(images)):\n","#                 if preds[i] == labels[i]:\n","#                     correct_examples.append((images[i].cpu(), labels[i].cpu(), preds[i].cpu()))\n","\n","#     if len(correct_examples) > num_samples:\n","#         correct_examples = random.sample(correct_examples, num_samples)\n","\n","#     if correct_examples:\n","#         fig, axes = plt.subplots(1, len(correct_examples), figsize=(15, 5))\n","#         for i, (image, label, pred) in enumerate(correct_examples):\n","#             image = image.permute(1, 2, 0)\n","#             image = image * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n","#             image = image.numpy().clip(0, 1)\n","#             axes[i].imshow(image)\n","#             axes[i].axis('off')\n","#             axes[i].set_title(\n","#                 f'Label: {test_data.classes[label.item()]}\\nPredicted: {test_data.classes[pred.item()]}',\n","#                 fontsize=12\n","#             )\n","#         plt.tight_layout()\n","#         plt.show()\n","\n","#     accuracy = accuracy_score(all_labels, all_preds)\n","#     precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n","#     recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n","#     f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n","\n","#     return accuracy, precision, recall, f1\n","\n","# def objective(trial):\n","#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n","#     batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n","#     epochs = trial.suggest_int(\"epochs\", 5, 10)\n","\n","#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n","\n","#     model = load_efficientnet_model(num_classes).to(device)\n","#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","#     criterion = nn.CrossEntropyLoss()\n","\n","#     for epoch in range(epochs):\n","#         model.train()\n","#         for images, labels in train_loader:\n","#             images, labels = images.to(device), labels.to(device)\n","#             optimizer.zero_grad()\n","#             outputs = model(images)\n","#             loss = criterion(outputs, labels)\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#     accuracy, _, _, _ = evaluate_model_and_plot_random_correct_examples(model, test_loader, device)\n","#     return accuracy\n","\n","# study = optuna.create_study(direction=\"maximize\")\n","# study.optimize(objective, n_trials=5)\n","\n","# best_params = study.best_params\n","# print(\"Best hyperparameters:\", best_params)\n","\n","# batch_size = best_params[\"batch_size\"]\n","# epochs = best_params[\"epochs\"]\n","# learning_rate = best_params[\"learning_rate\"]\n","\n","# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n","\n","# model = load_efficientnet_model(num_classes).to(device)\n","# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","# criterion = nn.CrossEntropyLoss()\n","\n","# for epoch in range(epochs):\n","#     print('epoch: ', epoch)\n","#     model.train()\n","#     for images, labels in train_loader:\n","#         images, labels = images.to(device), labels.to(device)\n","#         optimizer.zero_grad()\n","#         outputs = model(images)\n","#         loss = criterion(outputs, labels)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","# torch.save(model, \"/content/efficientnet_trained.pth\")\n","# print(\"EfficientNet model saved!\")\n","\n","# accuracy, precision, recall, f1 = evaluate_model_and_plot_random_correct_examples(model, test_loader, device)\n","# print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"],"metadata":{"id":"sKPdYwzF1nqa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Now upload the trained efficientNet hyperparameter from link:**\n","\n","**The name of this file is: efficientnet_trained.pth**"],"metadata":{"id":"AwAhTej222k5"}},{"cell_type":"code","source":["# Load the saved model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(\"/content/efficientnet_trained.pth\").to(device)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ai9KRTs42X8p","executionInfo":{"status":"ok","timestamp":1732682065305,"user_tz":300,"elapsed":613,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"ee2681c3-13af-41f2-d091-ba426e56a962"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n","            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n","            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n","      )\n","      (5): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n","            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n","            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.3, inplace=True)\n","    (1): Linear(in_features=1536, out_features=63, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# classify cropped images:\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","\n","preprocess = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","\n","test_dir = '/content/results/predict/crops/dummy'\n","\n","\n","# # Initialize metrics\n","# correct = 0\n","# total = 0\n","# total_loss = 0\n","# criterion = torch.nn.CrossEntropyLoss()\n","\n","# Prepare for plotting images\n","plot_images = []\n","# actual_labels = []\n","predicted_labels = []\n","\n","\n","# for root, dirs, files in os.walk('/content/dummy'):\n","#     if '.ipynb_checkpoints' in dirs:\n","#         dirs.remove('.ipynb_checkpoints')  # Skip the checkpoint directory\n","class_names = classes\n","food_vector = []\n","# Make predictions on test images\n","for img_file in os.listdir(test_dir):\n","    # category_path = os.path.join(test_dir, category)\n","    # if os.path.isdir(category_path):\n","        # for img_file in os.listdir(category_path):\n","            img_path = os.path.join(test_dir, img_file)\n","            print(img_path)\n","            image = Image.open(img_path)\n","            # Convert image to RGB if it has an alpha channel\n","            if image.mode != 'RGB':\n","                image = image.convert('RGB')\n","\n","            img_tensor = preprocess(image).unsqueeze(0).to(device)\n","            # true_label = food_class.index(category)\n","\n","\n","            with torch.no_grad():\n","              output = model(img_tensor)\n","              _, predicted_class = torch.max(output, 1)\n","              #plot_images.append(image)\n","              #predicted_labels.append(class_names[predicted_class.item()])\n","                # output = mobilenet(img_tensor)\n","                # predicted_index = output.argmax(dim=1).item()\n","                # predicted_label = food_class[predicted_index]\n","\n","                # Calculate loss\n","                # loss = criterion(output, torch.tensor([true_label]).to(device))\n","                # total_loss += loss.item()\n","\n","            # Update metrics\n","            # correct += (predicted_index == true_label)\n","            # total += 1\n","\n","            # Store for plotting\n","            plot_images.append(image)\n","            # actual_labels.append(category)\n","\n","            #print(f\"Predicted Class: {class_names[predicted_class.item()]}\")\n","            print(class_names[predicted_class.item()])\n","            food_vector.append(class_names[predicted_class.item()])\n","            predicted_labels.append(class_names[predicted_class.item()])\n","\n","            # plt.imshow(image)\n","            # plt.title(f'Actual: {category}, Predicted: {predicted_label}')\n","            # plt.axis('off')\n","            # plt.show()\n","\n","# Calculate accuracy and average loss\n","# accuracy = correct / total if total > 0 else 0\n","# average_loss = total_loss / total if total > 0 else 0\n","# error_rate = 1 - accuracy\n","\n","# Print the metrics\n","# print(f'Accuracy: {accuracy:.4f}')\n","# print(f'Average Loss: {average_loss:.4f}')\n","# print(f'Error Rate: {error_rate:.4f}')\n","\n","# Plotting images with actual and predicted labels\n","\n","num_images = len(plot_images)\n","print(num_images)\n","plt.figure(figsize=(5, num_images // 5 + 1))  # Adjust the figure height based on number of images\n","for i in range(num_images):\n","    plt.subplot(num_images // 5 + 1, 5, i + 1)  # Create a grid of subplots\n","    plt.imshow(plot_images[i])\n","    plt.title(f'Predicted: {predicted_labels[i]}')\n","    plt.axis('off')\n","\n","# plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"15olIVGx5jyY","executionInfo":{"status":"error","timestamp":1732686937607,"user_tz":300,"elapsed":326,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"15b29dce-42c3-4a2f-df71-963e0fcf045b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-64b689457fee>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# classify cropped images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":["food_vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJyYie2G60j-","executionInfo":{"status":"ok","timestamp":1732682659110,"user_tz":300,"elapsed":260,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"a39fd976-d71e-436b-db36-01d4b1202851"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['milk',\n"," 'beef',\n"," 'egg',\n"," 'bread',\n"," 'strawberry',\n"," 'carrot',\n"," 'yellow bell pepper',\n"," 'cabbage',\n"," 'bacon',\n"," 'eggplant',\n"," 'corn',\n"," 'spinach']"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"pes12017000148/food-ingredients-and-recipe-dataset-with-images\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bq7KvmRm9r9F","executionInfo":{"status":"ok","timestamp":1732683173595,"user_tz":300,"elapsed":17908,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"1b4c51a0-2499-48db-cf72-465dedb71c60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/pes12017000148/food-ingredients-and-recipe-dataset-with-images?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 206M/206M [00:10<00:00, 21.4MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/pes12017000148/food-ingredients-and-recipe-dataset-with-images/versions/1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import spacy\n","import time\n","\n","### GPU statement\n","try:\n","    spacy.require_gpu()\n","    print(\"GPU is available in the training.\")\n","except:\n","    print(\"GPU is not available, using CPU instead.\")\n","\n","# load the Spacy model\n","NER_SPACY = spacy.load(\"en_core_web_sm\")\n","\n","# the list of words in noun but not food ingredients\n","words_not_food_in_noun = {\n","              # \"cup\", \"teaspoon\", \"tablespoons\", \"cups\", \"ounce\", \"ounces\", \"pound\", \"pounds\", \"tsp\",\n","              # \"tbsp\", \"medium\", \"stick\", \"slices\", \"extract\", \"oz\", \"temperature\", \"room\", \"pieces\",\n","              # \"purpose\", \"total\", \"g\", \"ml\", \"lengthwise\", \"crosswise\", \"pinch\", \"½\", \"¼\", \"¾\",\n","              # \"package\", \"sprigs\", \"sticks\", \"halves\", \"inch\", \"bunch\", \"bunches\", \"parts\", \"quality\",\n","              # \"batch\", \"thermometer\", \"slice\", \"grind\", \"attachment\", \"wheel\", \"superfine\", \"quarts\",\n","              # \"baking\", \"ribbons\", \"dash\", \"layers\", \"cube\", \"skewers\", \"sheets\", \"moons\", \"round\",\n","              # \"rind\", \"top\", \"bottom\", \"height\", \"width\", \"diameter\", \"bias\", \"flameproof\",\n","              # \"rolling\", \"pin\", \"center\", \"frying\", \"mill\", \"maker\", \"heaping\", \"¼\", \"sticks\",\n","              # \"tops\", \"ends\", \"weights\", \"kitchen\", \"tool\", \"processor\", \"ramekins\", \"thickness\",\n","              # \"molds\", \"sheet\", \"paddle\", \"strip\", \"segments\", \"blocks\", \"form\", \"stand\",\n","              # \"lengths\", \"handle\", \"springform\", \"sheets\", \"platter\", \"knives\", \"blender\", \"mandoline\",\n","              # \"skillet\", \"strainer\", \"cast\", \"iron\", \"jar\", \"cans\", \"quart\", \"pint\", \"ruler\",\n","              # \"bottle\", \"mortar\", \"pestle\", \"sticks\", \"notes\", \"step\", \"layer\", \"loaf\",\n","              # \"pan\", \"batch\", \"inch\",  \"foil\", \"container\", \"tins\", \"shells\",\n","              # \"mold\", \"serving\", \"blender\", \"processor\", \"attachment\", \"form\", \"box\",\n","              # \"bowl\", \"spatula\", \"mixer\", \"wire\", \"frame\", \"plate\", \"sheet\",\n","              # \"nut\", \"oven\", \"tray\", \"cutter\", \"grater\", \"pot\", \"wok\", \"dough\", \"log\", \"weight\",\n","              # \"temperature\", \"reading\", \"minutes\", \"hours\", \"tables\", \"range\", \"measuring\", \"bag\",\n","              # \"envelope\", \"mat\", \"sprinkling\", \"tin\", \"edges\", \"ball\", \"circle\", \"seal\", \"quart\",\n","              # \"syrup\", \"slab\", \"bars\", \"kitchen\", \"molds\", \"ribs\", \"base\", \"lump\", \"skewer\",\n","              # \"thickness\", \"degree\", \"ladle\", \"grains\", \"milliliters\", \"gallon\", \"basting\", \"stem\",\n","              # \"tray\", \"handful\", \"frames\", \"loops\", \"bag\", \"label\"\n","              }\n","\n","# food ingredient word extracting\n","def food_word_extracting(ingredients_list, batch_size=32):\n","    food_extracted_output = []\n","    total_batch = (len(ingredients_list) +batch_size-1) // batch_size  ### calculate the total batch sizes\n","    start_time = time.time()\n","\n","    for batch_idx in range(0, len(ingredients_list), batch_size):\n","        ### seperate the total batch into [0,32],[32,64]....\n","        batch = ingredients_list[batch_idx:batch_idx + batch_size]\n","        batch_docs = list(NER_SPACY.pipe(batch))\n","        batch_output = []\n","\n","        ### the important steps, we ultilize the Spacy noun words extracting ability to extract nouns and propns from the sentences.\n","        ### one slice of the cake ----> \"cake\" will be extracted\n","        for doc in batch_docs:\n","            food_ing_words = []\n","            for token in doc:\n","                ### if the token is in the noun and propn and not in the word_not_food_in_noun list\n","                if token.pos_ in {\"NOUN\", \"PROPN\"} and token.text.lower() not in words_not_food_in_noun:\n","                    food_ing_words.append(token.text)\n","            batch_output.append(food_ing_words)\n","        food_extracted_output.extend(batch_output)\n","\n","        # print the logs\n","        time_cost = time.time() - start_time\n","        if (batch_idx // batch_size+1) % 100 == 0:  # print log every 10 batchs\n","            print(f\"Processed batch {batch_idx // batch_size+1}/{total_batch}. Time cost is : {time_cost:.2f} seconds\")\n","    total_time = time.time() - start_time\n","    print(f\"Word extracting process using NER completed in {total_time:.2f} seconds.\")\n","    return food_extracted_output\n","\n","# data loading\n","data_path = \"/root/.cache/kagglehub/datasets/pes12017000148/food-ingredients-and-recipe-dataset-with-images/versions/1\"\n","csv_file = os.path.join(data_path, \"Food Ingredients and Recipe Dataset with Image Name Mapping.csv\")\n","df = pd.read_csv(csv_file)\n","\n","# data cleaning\n","df = df.dropna(subset=['Cleaned_Ingredients', 'Title', 'Instructions'])\n","df = df.drop_duplicates(subset=['Title'])\n","\n","### Standardize the cleaned_ingredients column (the improving step: we use the Spacy ner network to do the word extracting)\n","ingre_cleaned_merge = []\n","for cleaned_ingredients in df['Cleaned_Ingredients']:\n","    # use eval function and ' ' to merge every word into a sentence with the form of python list\n","    combined_text = \" \".join(eval(cleaned_ingredients))\n","    ingre_cleaned_merge.append(combined_text)\n","\n","# use food_extracting function to extract the food words in the merged sentences\n","ingredients_list = food_word_extracting(ingre_cleaned_merge)\n","df['Ingredients_list'] = ingredients_list\n","\n","# input vector from YOLO output\n","YOLO_detected_ingredients = food_vector\n","\n","# collect all ingredients from the ingredients list\n","ingredient_list_total = set()\n","for ingredients in df['Ingredients_list']:\n","    for ingredient in ingredients:\n","        if ingredient.strip():\n","            ingredient_list_total.add(ingredient)\n","\n","# merge the YOLO food ingredient into the ingredient_list_total\n","ingredient_list_total.update(YOLO_detected_ingredients)\n","\n","### use the ingredients as the labels of our MLB\n","mlb = MultiLabelBinarizer(classes=list(ingredient_list_total))\n","ingredient_vectors = mlb.fit_transform(df['Ingredients_list'])\n","\n","# convert YOLO vector into the one hot encoding\n","YOLO_vector_one_hot = mlb.transform([YOLO_detected_ingredients])[0]\n","\n","# calculate the cosine similarity\n","cos_sim = cosine_similarity([YOLO_vector_one_hot], ingredient_vectors).flatten()\n","\n","## exclude the recipe with cosine similarity 0\n","non_zero_indices = cos_sim > 0\n","filtered_cos_sim = cos_sim[non_zero_indices]\n","filtered_indices = non_zero_indices.nonzero()[0]\n","\n","# sort recipes without 0 cosine similarity and get the top 5 recipes\n","top_5_recipe_idx = filtered_cos_sim.argsort()[-5:][::-1]\n","top_5_recipe_idx_filtered = filtered_indices[top_5_recipe_idx]\n","top_5_recipes = df.iloc[top_5_recipe_idx_filtered]\n","\n","### output adjust function, adjust the output display\n","def output_adjust(text, line_length=160):\n","    words = text.split()\n","    text_adjust = \"\"\n","    line = \"\"\n","    for word in words:\n","        if len(line) + len(word) + 1 > line_length:\n","            text_adjust += line + \"\\n\"\n","            line = word\n","        else:\n","            if line:\n","                line += \" \" + word\n","            else:\n","                line = word\n","    text_adjust += line\n","    return text_adjust\n","\n","# print the output\n","print(\"Top 5 Recommended Recipes based on the food detection in fridge:\")\n","for i, index in enumerate(top_5_recipe_idx_filtered, start=1):\n","    title = df.iloc[index]['Title']\n","    instructions = df.iloc[index]['Instructions']\n","    ingredients = df.iloc[index]['Cleaned_Ingredients']\n","    similarity = cos_sim[index]\n","    formatted_instructions = output_adjust(instructions)\n","    ingredients = output_adjust(ingredients)\n","    print(f\"Top{i}. Title: {title}, Cosine Similarity: {similarity:.4f}\\n\")\n","    print(f\"Ingredients:\\n{ingredients}\\n\")\n","    print(f\"Instructions:\\n{formatted_instructions}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W195UXPp7z4x","executionInfo":{"status":"ok","timestamp":1732683255044,"user_tz":300,"elapsed":76729,"user":{"displayName":"Zha Yixin","userId":"06538431514083436016"}},"outputId":"35fa5a71-824e-4c7d-ac59-d8134285c3f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available in the training.\n","Processed batch 100/416. Time cost is : 27.97 seconds\n","Processed batch 200/416. Time cost is : 44.95 seconds\n","Processed batch 300/416. Time cost is : 58.21 seconds\n","Processed batch 400/416. Time cost is : 71.48 seconds\n","Word extracting process using NER completed in 73.19 seconds.\n","Top 5 Recommended Recipes based on the food detection in fridge:\n","Top1. Title: Teeny-Weeny Coxinha, Cosine Similarity: 0.2635\n","\n","Ingredients:\n","['1 quart vegetable oil, for frying', '3 1/2 cups low-sodium chicken broth', '1 onion, peeled and quartered', '1 carrot, peeled and quartered', '1 celery rib,\n","quartered', '1 large chicken breast', '8 ounces packaged cream cheese, softened', '1 ear corn, kernels cut off the cob', '2 green onions, thinly sliced', '1\n","garlic clove, minced', 'Salt and pepper, to taste', '1/2 tablespoon extra-virgin olive oil', '2 cups all-purpose flour', '1 egg', '1 tablespoon whole milk', '1\n","cup plain Italian bread crumbs', 'Salt and pepper', 'to taste']\n","\n","Instructions:\n","1. In a large pot, preheat oil to 350°F. In another large pot, combine broth, onions, carrots, and celery and bring to a simmer. Carefully add chicken, cover,\n","and reduce heat to medium-low. Poach chicken for 12 to 15 minutes, or until just cooked through. Turn off heat, but leave the pot of hot poaching liquid on the\n","stove. Remove chicken from liquid and let it rest for 10 minutes. 2. For the filling, finely chop or shred chicken into a large mixing bowl. Add cream cheese,\n","corn, green onions, and garlic. Season with salt and pepper. Fold to combine. 3. Strain 1 1/2 cups of the poaching liquid and discard the rest. In a saucepan\n","over high heat, bring reserved liquid and oil to a boil. Add flour and stir vigorously until dough forms. Turn dough out onto a lightly floured surface and\n","knead until smooth, about 5 minutes. Roll out to 1/4 inch thick. Cut out small rounds using a 3-inch circle cutter or the rim of a round cup. Place a small\n","scoop (about 1 tablespoon) of the filling in the center of each round. Pinch dough together at the top to seal, creating plump little teardrop-shaped pouches.\n","In a small bowl, lightly whisk eggs and milk together. Place bread crumbs in another small bowl. Carefully dip each pouch into the egg wash and then the bread\n","crumbs until fully coated. Fry coxinha in small batches for 7 to 9 minutes, or until golden brown. Drain on paper towels, lightly season with salt, and serve\n","hot.\n","\n","Top2. Title: Not-So-Basic Meatloaf, Cosine Similarity: 0.2592\n","\n","Ingredients:\n","['5 strips lean bacon, finely chopped', '6 cloves garlic, minced', '2 medium onions, finely chopped', '1 medium carrot, finely chopped', '2 pounds very lean\n","ground beef sirloin', '2 large eggs', '1/2 cup milk', '1 cup finely ground fresh bread crumbs', '1/4 cup Dijon mustard', '1/4 cup barbecue sauce', '1 tablespoon\n","bottled horseradish, well drained', '1/2 cup finely chopped fresh flat-leaf parsley', '2 tablespoons coarse salt', '1 tablespoon freshly ground black pepper',\n","'1 teaspoon finely minced fresh thyme (or 1/4 teaspoon dried thyme)', '2 to 3 cups croutons', '10 whole, unpeeled, garlic cloves', '4 bay leaves', '1 sprig\n","fresh thyme']\n","\n","Instructions:\n","Preheat the oven to 375 degrees. Place the bacon in a medium sauté pan over medium-low heat. Sauté the bacon for about 5 minutes, or until it has begun to crisp\n","and most of the fat has rendered out. Add the garlic, onion, and carrot and continue to sauté for about 4 minutes, or until the vegetables are soft and the\n","onions are translucent but have not taken on any color. Remove the pan from the heat and allow the vegetables to cool (see Note). Place the ground sirloin into\n","a large mixing bowl. Add the eggs and milk and, using your hands, work the liquid into the meat. Add the bread crumbs and continue to work the liquid and crumbs\n","into the meat. Add the cooled vegetables, mustard, barbecue sauce, and horseradish along with 1/4 cup of the parsley, salt, pepper, and thyme. Using your hands,\n","gently work all of the ingredients into the meat until well combined. Place one-half of the croutons into a shallow baking dish at least 14 inches long.\n","Transfer the meatloaf mixture onto a clean, flat surface and, again, using your hands, shape it into a loaf about 3 1/4 inches wide X 2 1/2 inches high X 12\n","inches long (or into a round, breadlike form, a letter of the alphabet, an oval, or into several small loaves). Press the remaining croutons into the loaf,\n","making sure that they are partially pressed down into it. Gently press the unpeeled garlic cloves into the top of the meatloaf. Carefully lay the loaf on top of\n","the croutons in the baking dish (you might need to use a couple of spatulas to facilitate this), reforming the shape with your hands, if necessary. Pierce the\n","meatloaf with the bay leaves and thyme sprig. Place the meatloaf in the preheated oven and bake for 1 hour, or until the internal temperature reads 165 degrees\n","on an instant-read thermometer and the top is nicely browned. Remove the pan from the oven. Allow the meatloaf to rest for about 5 minutes before transferring\n","it to a serving platter. Remove the bay leaves and thyme sprig and sprinkle the remaining parsley over the top of the loaf and around the platter. Cut crosswise\n","into 1-inch, or thicker, slices and serve.\n","\n","Top3. Title: Arugula, Bacon, and Gruyère Bread Pudding, Cosine Similarity: 0.2582\n","\n","Ingredients:\n","['1 1/2 cups whole milk', '1/2 cup heavy cream', '5 large eggs', '6 bacon slices', '1 large shallot, finely chopped', '3 garlic cloves, chopped', '7 ounces baby\n","arugula or baby spinach (6 1/2 cups)', '6 cups cubed (1-inch) country-style bread (1 pound)', '5 1/2 ounces Gruyère cheese', 'coarsely grated (1 1/2 cups)']\n","\n","Instructions:\n","Preheat oven to 375°F with rack in middle. Butter a 2-qt shallow baking dish. Whisk together milk, cream, eggs, and 1/4 teaspoon each of salt and pepper in a\n","large bowl. Cook bacon in a 12-inch heavy skillet over medium heat, turning occasionally, until crisp. Transfer with tongs to paper towels to drain, then\n","coarsely crumble. Pour off all but 1 tablespoon fat from skillet. Increase heat to medium-high and cook shallot and garlic, stirring constantly, until golden,\n","about 1 minute. Gradually add arugula and cook, stirring, until it wilts. Stir arugula mixture, bacon, bread, and cheese into custard. Transfer to baking dish\n","and cover with foil. Bake 30 minutes, then remove foil and bake until golden in spots, about 10 minutes more.\n","\n","Top4. Title: Meatloaf, Cosine Similarity: 0.2552\n","\n","Ingredients:\n","['1 cup fine fresh bread crumbs (from 2 slices firm white sandwich bread)', '1/3 cup whole milk', '1 medium onion, finely chopped', '3 garlic cloves, minced',\n","'1 medium celery rib, finely chopped', '1 medium carrot, finely chopped', '2 tablespoons unsalted butter', '2 tablespoons Worcestershire sauce', '1 tablespoon\n","cider vinegar', '1/4 teaspoon ground allspice', '1/4 pound bacon (about 4 slices), chopped', '1/2 cup pitted prunes, chopped', '1 1/2 pounds ground beef chuck',\n","'1/2 pound ground pork (not lean)', '2 large eggs', '1/3 cup finely chopped flat-leaf parsley', 'Garnish: cooked bacon']\n","\n","Instructions:\n","Preheat oven to 350°F with rack in middle. Soak bread crumbs in milk in a large bowl. Meanwhile, cook onion, garlic, celery, and carrot in butter in a large\n","heavy skillet over medium heat, stirring occasionally, 5 minutes. Cover skillet and reduce heat to low, then cook until carrot is tender, about 5 minutes.\n","Remove from heat and stir in Worcestershire sauce, vinegar, allspice, 2 teaspoons salt, and 1 1/2 teaspoons pepper. Add to bread-crumb mixture. Finely chop\n","bacon and prunes in a food processor, then add to onion mixture along with beef, pork, eggs, and parsley and mix together with your hands. Pack mixture into a\n","9- by 5-inch oval loaf in a 13- by 9-inch shallow baking dish or pan. Bake until an instant-read thermometer inserted into center of meatloaf registers 155°F, 1\n","to 1 1/4 hours. Let stand 10 minutes before serving.\n","\n","Top5. Title: Spinach Gnocchi, Cosine Similarity: 0.2500\n","\n","Ingredients:\n","['10 ounces block frozen chopped spinach', '1 cup whole milk ricotta cheese', '2/3 cup parmesan cheese, plus 2 tbsp for sprinkling before serving.', '1 egg\n","yolk', '2 tablespoons flour', 'plus more for dusting your hands while rolling']\n","\n","Instructions:\n","Defrost the brick of frozen spinach (you can also do this in the microwave). Squeeze ALL (and I mean ALL) of the water out of the spinach in small handfuls (I\n","use my hands and do it over a bowl to make sure I don't lose any spinach). Place all of the ingredients in a food processor and pulse. You want to make sure the\n","spinach is in tiny pieces and the mixture is thoroughly combined. Dust your hands with a little flour so the mixture doesn't stick to your hands. Take 1\n","teaspoon of the spinach mixture and roll into tiny balls. Place on a plate covered with waxed paper or parchment. Bring a large pot of water to a boil for\n","cooking the gnocchi. Add the gnocchi to the water in batches and cook for 3 minutes or until they rise to the surface. Using a slotted spoon, remove the gnocchi\n","to a plate or bowl. Sprinkle with parmesan cheese, cool and serve. To Freeze: After step 5, place on sheet tray and freeze for 30 minutes. Transfer to a ziploc\n","bag, label and freeze up to 4 months. When ready, thaw to room temperature and follow steps 6-9.\n","\n"]}]},{"cell_type":"code","source":["print(\" Cleaned ingredient list[5] Using SPACY:\")\n","ingredients = df['Ingredients_list'].iloc[5]\n","line_length = 9\n","for i in range(0, len(ingredients), line_length):\n","    print(ingredients[i:i + line_length])"],"metadata":{"id":"n6r2zxP_8g3B"},"execution_count":null,"outputs":[]}]}